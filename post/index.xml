<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Stanford RL Forum</title>
    <link>https://97hongjun.github.io/post/</link>
    <description>Recent content in Posts on Stanford RL Forum</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://97hongjun.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reinforcement Learning, Bit by Bit</title>
      <link>https://97hongjun.github.io/p/rl-bit-by-bit/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/rl-bit-by-bit/</guid>
      <description>Presenter  Xiuyuan (Lucy) Lu
Research Scientist,
DeepMind, Mountain View
Abstract  Reinforcement learning agents have demonstrated remarkable achievements in simulated environments. Data efficiency poses an impediment to carrying this success over to real environments. The design of data-efficient agents calls for a deeper understanding of information acquisition and representation. We develop concepts and establish a regret bound that together offer principled guidance. The bound sheds light on questions of what information to seek, how to seek that information, and what information to retain.</description>
    </item>
    
    <item>
      <title>Provable Model-based Nonlinear Bandit and Reinforcement Learning</title>
      <link>https://97hongjun.github.io/p/provable-model-based-bandit-rl/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/provable-model-based-bandit-rl/</guid>
      <description>Presenter  Tengyu Ma
Assistant Professor of Computer Science and Statistics,
Stanford
Abstract  Deep model-based reinforcement learning methods have achieved state-of-the-art sample efficiency but we lack a theoretical understanding of them. This talk will first show that convergence to a global maximum requires an exponential number of samples even for a one-layer neural net bandit problem, which is strictly easier than RL. Therefore, we propose to study convergence to local maxima.</description>
    </item>
    
    <item>
      <title>Diffusion Asymptotics for Sequential Experiments</title>
      <link>https://97hongjun.github.io/p/diffusion-asymptotic-sequential-exp/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/diffusion-asymptotic-sequential-exp/</guid>
      <description>Presenter  Kuang Xu
Associate Professor of Operations, Information and Technology,
Stanford Graduate School of Business
Abstract  I will discuss in this talk a new diffusion-asymptotic analysis for sequentially randomized experiments. Rather than taking sample size n to infinity while keeping the problem parameters fixed, we let the mean signal level scale to the order 1/\sqrt{n} so as to preserve the difficulty of the learning task as n gets large.</description>
    </item>
    
    <item>
      <title>Lectures on Information Directed Sampling</title>
      <link>https://97hongjun.github.io/p/lec-ids/</link>
      <pubDate>Mon, 11 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/lec-ids/</guid>
      <description>Presenter  Tor Lattimore
Research Scientist,
Deepmind, London
Abstract  Tor will give a whirlwind tour of a series of recent papers on the information directed sampling algorithm for sequential decision-making. The results come in three flavours. First, generalising and applying the IDS algorithm to problems with a rich information structure such as convex bandits and partial monitoring. Second, showing a connection between the optimisation problem solved by IDS and the optimisation problem that determines the asymptotic lower bound for stochastic structured bandit problems.</description>
    </item>
    
  </channel>
</rss>
